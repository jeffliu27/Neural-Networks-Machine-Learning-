{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Neural Networks using Numpy [14 pts.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Helper Functions [4 pts]\n",
    "\n",
    "1. ReLU(): This function will accept one argument and return Numpy array with the ReLU\n",
    "activation and the equation is given below. [0.5 pt]\n",
    "ReLU(x) = max(x, 0)\n",
    "2. softmax(): This function will accept one argument and return a Numpy array with the\n",
    "softmax activations of each of the inputs and the equation is shown below. [0.5 pt]\n",
    "3. compute(): This function will accept 3 arguments: a weight, an input, and a bias matrix\n",
    "and return the product between the weights and input, plus the biases (i.e. a prediction for\n",
    "a given layer). [0.5 pt]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dev_j\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "# Load the data\n",
    "def loadData():\n",
    "    with np.load(\"notMNIST.npz\") as data:\n",
    "        Data, Target = data[\"images\"], data[\"labels\"]\n",
    "        np.random.seed(521)\n",
    "        randIndx = np.arange(len(Data))\n",
    "        np.random.shuffle(randIndx)\n",
    "        Data = Data[randIndx] / 255.0\n",
    "        Target = Target[randIndx]\n",
    "        trainData, trainTarget = Data[:10000], Target[:10000]\n",
    "        validData, validTarget = Data[10000:16000], Target[10000:16000]\n",
    "        testData, testTarget = Data[16000:], Target[16000:]\n",
    "    return trainData, validData, testData, trainTarget, validTarget, testTarget\n",
    "\n",
    "# Implementation of a neural network using only Numpy - trained using gradient descent with momentum\n",
    "def convertOneHot(trainTarget, validTarget, testTarget):\n",
    "    newtrain = np.zeros((trainTarget.shape[0], 10))\n",
    "    newvalid = np.zeros((validTarget.shape[0], 10))\n",
    "    newtest = np.zeros((testTarget.shape[0], 10))\n",
    "\n",
    "    for item in range(0, trainTarget.shape[0]):\n",
    "        newtrain[item][trainTarget[item]] = 1\n",
    "    for item in range(0, validTarget.shape[0]):\n",
    "        newvalid[item][validTarget[item]] = 1\n",
    "    for item in range(0, testTarget.shape[0]):\n",
    "        newtest[item][testTarget[item]] = 1\n",
    "    return newtrain, newvalid, newtest\n",
    "\n",
    "\n",
    "def shuffle(trainData, trainTarget):\n",
    "    np.random.seed(421)\n",
    "    randIndx = np.arange(len(trainData))\n",
    "    target = trainTarget\n",
    "    np.random.shuffle(randIndx)\n",
    "    data, target = trainData[randIndx], target[randIndx]\n",
    "    return data, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 28, 28)\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "trainData, validData, testData, trainTarget, validTarget, testTarget = loadData()\n",
    "trainTarget, validTarget, testTarget = convertOneHot(trainTarget, validTarget, testTarget)\n",
    "print(trainData.shape)\n",
    "print(trainTarget[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReLu(x):\n",
    "    x[x<0] = 0\n",
    "    return np.array(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradReLu(x):\n",
    "    x[x>0] = 1\n",
    "    x[x<=0] = 0\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    x = np.exp(x)/np.sum(np.exp(x))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute(X, W, b):\n",
    "    return np.matmul(X, W) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def averageCE(target, prediction):\n",
    "    prediction = softmax(prediction)\n",
    "    total = np.sum(target * np.log(prediction))\n",
    "    avg = total * (-1/len(target))\n",
    "    return avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradCE(target, prediction):\n",
    "    total = np.sum(target * np.divide(1,softmax(prediction)))\n",
    "    gradCE = total * (-1/len(target))\n",
    "    return gradCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradSoftmax(s):\n",
    "    s = softmax(s).reshape(-1, 1)\n",
    "    print(\"in softmax\", s.shape)\n",
    "    return np.diagflat(s) - np.dot(s, np.transpose(s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Backpropagation Derivation [4 pts.]\n",
    "To train the neural network, you will need to implement the backpropagation algorithm. For the\n",
    "neural network architecture outlined in the assignment description, derive the following analytical\n",
    "expressions and include them in your report:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myNN():\n",
    "    def __init__(self, num_hidden):\n",
    "        super(myNN, self).__init__()\n",
    "        \n",
    "        n_x = 784 # size of input layer`\n",
    "        k = num_hidden\n",
    "        n_y = 10 # size of output layer\n",
    "        \n",
    "        #initialize parameters\n",
    "        self.W1 = np.random.randn(n_x, k) * (2 / (n_x + k))**(1/2.0) #Wh\n",
    "        self.b1 = np.zeros(shape=(1,k))\n",
    "        self.W2 = np.random.randn(k,n_y) * (2 / (k + n_y))**(1/2.0) #Wo\n",
    "        self.b2 = np.zeros(shape=(1,n_y))\n",
    "        \n",
    "        #initialize hidden units and signals\n",
    "        self.X0 = np.zeros(shape=(1,n_x))\n",
    "        self.X1 = np.zeros(shape=(1,k))\n",
    "        self.X2 = np.zeros(shape=(1,n_y))\n",
    "        self.S1 = np.zeros(shape=(1,k))\n",
    "        self.S2 = np.zeros(shape=(1,n_y))\n",
    "        \n",
    "        #for back propagation\n",
    "        self.V2_w = np.full((n_x, k), 1e-5)\n",
    "        self.V1_w = np.full((k, n_y), 1e-5)\n",
    "        self.V2_b = np.full((1, n_y), 1e-5)\n",
    "        self.V1_b = np.full((1, k), 1e-5)\n",
    "        self.gamma = 0.9\n",
    "        self.alpha = 1 - self.gamma\n",
    "        \n",
    "    def forward(self, img):\n",
    "        self.X0 = img\n",
    "        # Implement Forward Propagation to calculate A2 (probabilities)\n",
    "#         S1 = np.dot(W1,X0) + b1 # replace with compute\n",
    "        self.S1 = compute(self.X0, self.W1, self.b1)\n",
    "#         X1 = np.tanh(S1) #replace with relu\n",
    "        self.X1 = ReLu(self.S1)\n",
    "#         S2 = np.dot(W2,X1) + b2 # replace with compute\n",
    "        self.S2 = compute(self.X1, self.W2, self.b2)\n",
    "#         X2 = sigmoid(S2) # replace with SOFTMAX\n",
    "        self.X2 = softmax(self.S2)\n",
    "    \n",
    "        return self.X2\n",
    "    \n",
    "    def backward(self, target):\n",
    "        print(\"delta2:\", target.shape, self.X2.shape, self.S2.shape)\n",
    "        print(gradCE(target, self.X2).shape, gradSoftmax(self.S2).shape)\n",
    "        delta2 = np.multiply(gradCE(target, self.X2),gradSoftmax(self.S2))\n",
    "        print(delta2.shape, self.S1.shape, self.W2.shape)\n",
    "        delta1 = np.multiply(np.matmul(self.W2,delta2), gradReLu(self.S1))\n",
    "        \n",
    "        d_W2 = np.matmul(self.X1.T,delta2) \n",
    "        d_b2 = delta2\n",
    "        d_W1 = np.matmul(self.X0.T,delta1)\n",
    "        d_b1 = delta1\n",
    "        \n",
    "        self.V2_w = self.gamma * self.V2_w + self.alpha * d_W2\n",
    "        self.V2_b = self.gamma * self.V2_b + self.alpha * d_b2\n",
    "        \n",
    "        self.V1_w = self.gamma * self.V1_w + self.alpha * d_W1\n",
    "        self.V1_b = self.gamma * self.V1_b + self.alpha * d_b1\n",
    "        return \n",
    "    def update(self):\n",
    "        self.W1 = self.W1 = self.V1_w\n",
    "        self.b1 = self.b1 = self.V1_b\n",
    "        self.W2 = self.W2 = self.V2_w\n",
    "        self.b2 = self.b2 = self.V2_b\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(model, data, target):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for image, label in zip(data, target):\n",
    "        output = model(image)  \n",
    "        pred = np.argmax(output)\n",
    "        correct += pred.eq(label.view_as(pred)).sum().item()       \n",
    "        total += img.shape[0]\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,trainData, validData, testData, trainTarget, validTarget, testTarget, num_epochs = 10):\n",
    "    # initialize all the weights\n",
    "    losses, valid_losses, train_acc, valid_acc = [], [], [], []\n",
    "    epochs = []\n",
    "    \n",
    "    assert trainData.shape[0] == 10000\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss = 0\n",
    "        for image, label in zip(trainData, trainTarget):\n",
    "            label = np.reshape(label, (1, 10))\n",
    "            print(\"sup\")\n",
    "            image = np.reshape(image, (1, 784))\n",
    "            \n",
    "            \n",
    "            pred = model.forward(image)\n",
    "            print(pred.shape)\n",
    "            print(label.shape)\n",
    "            loss = averageCE(label, pred)\n",
    "            train_loss += loss/(trainData.shape[0])\n",
    "            model.backward(label)\n",
    "            \n",
    "            model.update()\n",
    "    \n",
    "    \n",
    "        valid_loss = 0\n",
    "        for image, label in zip(validData, validTarget):\n",
    "            image = np.reshape(image, (1, 784))\n",
    "            label = label.T\n",
    "            \n",
    "            pred = model(image)\n",
    "            valid_loss += averageCE(label, pred)/(validData.shape[0])\n",
    "            \n",
    "        valid_losses.append(float(valid_loss)) \n",
    "            \n",
    "        losses.append(float(train_loss))\n",
    "\n",
    "        epochs.append(epoch)\n",
    "        train_acc.append(get_accuracy(model, trainData,trainTarget ))\n",
    "        valid_acc.append(get_accuracy(model, validData, validTarget))\n",
    "        print(\"Epoch %d; Loss %f; Train Acc %f; Val Acc %f\" % (\n",
    "              epoch+1, loss, train_acc[-1], valid_acc[-1]))\n",
    "        \n",
    "     # plotting\n",
    "    plt.title(\"Training Curve\")\n",
    "    plt.plot(epochs, losses, label=\"Train\")\n",
    "    plt.plot(epochs, valid_losses, label=\"Validation\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.show()\n",
    "\n",
    "    plt.title(\"Training Curve\")\n",
    "    plt.plot(epochs, train_acc, label=\"Train\")\n",
    "    plt.plot(epochs, valid_acc, label=\"Validation\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sup\n",
      "(1, 10)\n",
      "(1, 10)\n",
      "delta2: (1, 10) (1, 10) (1, 10)\n",
      "in softmax (10, 1)\n",
      "() (10, 10)\n",
      "in softmax (10, 1)\n",
      "(10, 10) (1, 1000) (1000, 10)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (1000,10) (1,1000) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-162-38838e8c665f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmodel1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmyNN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrainData\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidData\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtestData\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainTarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidTarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtestTarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-161-cee1863fbd49>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, trainData, validData, testData, trainTarget, validTarget, testTarget, num_epochs)\u001b[0m\n\u001b[0;32m     19\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maverageCE\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m             \u001b[0mtrain_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainData\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m             \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-159-aa5c4da1f7eb>\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, target)\u001b[0m\n\u001b[0;32m     47\u001b[0m         \u001b[0mdelta2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgradCE\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mX2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mgradSoftmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mS2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdelta2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mS1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mW2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m         \u001b[0mdelta1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mW2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdelta2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradReLu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mS1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m         \u001b[0md_W2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mX1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdelta2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (1000,10) (1,1000) "
     ]
    }
   ],
   "source": [
    "model1 = myNN(1000)\n",
    "train(model1,trainData, validData, testData, trainTarget, validTarget, testTarget, num_epochs = 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
